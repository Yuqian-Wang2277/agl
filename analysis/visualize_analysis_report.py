#!/usr/bin/env python3
"""Visualize analysis_report.xlsx into charts.

This script reads the Excel report generated by analyze_validation.py and
produces chart PNG files in an output directory.

It intentionally avoids external Excel dependencies (openpyxl/pandas) so it can
run in minimal environments by parsing .xlsx XML directly.

Usage:
    python visualize_analysis_report.py /path/to/analysis_report.xlsx
    python visualize_analysis_report.py /path/to/analysis_report.xlsx --output-dir ./charts --top-n 10
"""

from __future__ import annotations

import argparse
import os
import re
import zipfile
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from xml.etree import ElementTree as ET

import matplotlib.pyplot as plt
import numpy as np

NS_MAIN = "http://schemas.openxmlformats.org/spreadsheetml/2006/main"
NS_DOC_REL = "http://schemas.openxmlformats.org/officeDocument/2006/relationships"
NS_PKG_REL = "http://schemas.openxmlformats.org/package/2006/relationships"

CATEGORIES = ["ID", "OOD", "HARD"]
CAT_COLORS = {"ID": "#1f77b4", "OOD": "#ff7f0e", "HARD": "#2ca02c"}


@dataclass
class SheetData:
    """Sheet cell map: row -> col -> value."""

    cells: Dict[int, Dict[int, str]]

    def get(self, row: int, col: int, default: str = "") -> str:
        return self.cells.get(row, {}).get(col, default)


def _col_from_ref(cell_ref: str) -> int:
    """Convert A1-style cell reference to 1-based column index."""
    m = re.match(r"([A-Z]+)\d+$", cell_ref)
    if not m:
        return 1
    col_letters = m.group(1)
    col = 0
    for ch in col_letters:
        col = col * 26 + (ord(ch) - ord("A") + 1)
    return col


def _parse_shared_strings(zf: zipfile.ZipFile) -> List[str]:
    if "xl/sharedStrings.xml" not in zf.namelist():
        return []
    root = ET.fromstring(zf.read("xl/sharedStrings.xml"))
    out: List[str] = []
    for si in root.findall(f"{{{NS_MAIN}}}si"):
        # Support rich text (<r><t>) and plain (<t>)
        texts = [t.text or "" for t in si.findall(f".//{{{NS_MAIN}}}t")]
        out.append("".join(texts))
    return out


def _parse_sheet_xml(xml_bytes: bytes, shared_strings: List[str]) -> SheetData:
    root = ET.fromstring(xml_bytes)
    sheet_data = root.find(f"{{{NS_MAIN}}}sheetData")
    cells: Dict[int, Dict[int, str]] = {}
    if sheet_data is None:
        return SheetData(cells=cells)

    for row in sheet_data.findall(f"{{{NS_MAIN}}}row"):
        r_idx = int(row.attrib.get("r", "0"))
        row_map: Dict[int, str] = {}
        for c in row.findall(f"{{{NS_MAIN}}}c"):
            ref = c.attrib.get("r", "")
            c_idx = _col_from_ref(ref)
            c_type = c.attrib.get("t")

            value = ""
            if c_type == "inlineStr":
                # <is><t>...
                texts = [t.text or "" for t in c.findall(f".//{{{NS_MAIN}}}t")]
                value = "".join(texts)
            else:
                v = c.find(f"{{{NS_MAIN}}}v")
                raw = v.text if v is not None and v.text is not None else ""
                if c_type == "s":
                    try:
                        value = shared_strings[int(raw)]
                    except Exception:
                        value = ""
                else:
                    value = raw
            row_map[c_idx] = value
        cells[r_idx] = row_map
    return SheetData(cells=cells)


def load_xlsx_sheets(xlsx_path: str) -> Dict[str, SheetData]:
    """Load all sheets from an xlsx file into cell maps."""
    with zipfile.ZipFile(xlsx_path) as zf:
        shared_strings = _parse_shared_strings(zf)

        workbook = ET.fromstring(zf.read("xl/workbook.xml"))
        rels = ET.fromstring(zf.read("xl/_rels/workbook.xml.rels"))

        rid_to_target: Dict[str, str] = {}
        for rel in rels.findall(f"{{{NS_PKG_REL}}}Relationship"):
            rid = rel.attrib.get("Id", "")
            target = rel.attrib.get("Target", "")
            if target.startswith("/"):
                target = target[1:]
            else:
                target = f"xl/{target}" if not target.startswith("xl/") else target
            rid_to_target[rid] = target

        sheets: Dict[str, SheetData] = {}
        for sh in workbook.findall(f".//{{{NS_MAIN}}}sheet"):
            name = sh.attrib.get("name", "")
            rid = sh.attrib.get(f"{{{NS_DOC_REL}}}id", "")
            target = rid_to_target.get(rid)
            if not name or not target or target not in zf.namelist():
                continue
            sheets[name] = _parse_sheet_xml(zf.read(target), shared_strings)
        return sheets


def _parse_steps(sample_sheet: SheetData) -> List[int]:
    steps: List[int] = []
    col = 2
    while True:
        text = sample_sheet.get(1, col).strip()
        if not text:
            break
        m = re.search(r"Step\s+(\d+)", text)
        if m:
            steps.append(int(m.group(1)))
        col += 1
    if not steps:
        raise ValueError("Failed to parse step list from sheet '样本数' row 1.")
    return steps


def _parse_trend_cell(text: str, expected_len: int) -> List[float]:
    parts = [p.strip() for p in re.split(r"[→>]+", text) if p.strip()]
    vals: List[float] = []
    for p in parts:
        try:
            vals.append(float(p))
        except ValueError:
            vals.append(float("nan"))
    if len(vals) < expected_len:
        vals.extend([float("nan")] * (expected_len - len(vals)))
    if len(vals) > expected_len:
        vals = vals[:expected_len]
    return vals


def _parse_category_metric_trends(
    sheet: SheetData,
    col_to_metric: Dict[int, str],
    steps_len: int,
) -> Dict[str, Dict[str, List[float]]]:
    data: Dict[str, Dict[str, List[float]]] = {m: {} for m in col_to_metric.values()}
    for row in (3, 4, 5):
        cat = sheet.get(row, 1).strip()
        if cat not in CATEGORIES:
            continue
        for col, metric_name in col_to_metric.items():
            trend_text = sheet.get(row, col).strip()
            data[metric_name][cat] = _parse_trend_cell(trend_text, steps_len)
    return data


def _parse_sample_counts(sample_sheet: SheetData, steps_len: int) -> Dict[str, List[float]]:
    out: Dict[str, List[float]] = {}
    for row in (2, 3, 4, 5):
        cat = sample_sheet.get(row, 1).strip()
        if not cat:
            continue
        vals: List[float] = []
        for col in range(2, 2 + steps_len):
            raw = sample_sheet.get(row, col).strip()
            try:
                vals.append(float(raw))
            except ValueError:
                vals.append(float("nan"))
        out[cat] = vals
    return out


def _parse_problem_breakdown(detail_sheet: Optional[SheetData]) -> Dict[str, List[Dict[str, float | str]]]:
    result: Dict[str, List[Dict[str, float | str]]] = {c: [] for c in CATEGORIES}
    if detail_sheet is None:
        return result

    row = 3
    while True:
        cat = detail_sheet.get(row, 1).strip()
        ptype = detail_sheet.get(row, 2).strip()
        if not cat and not ptype:
            break
        if cat in CATEGORIES and ptype and ptype != "小计":
            try:
                n = float(detail_sheet.get(row, 3).strip() or "nan")
                acc = float(detail_sheet.get(row, 4).strip() or "nan")
                avg_final = float(detail_sheet.get(row, 5).strip() or "nan")
                avg_fmt = float(detail_sheet.get(row, 6).strip() or "nan")
                avg_corr = float(detail_sheet.get(row, 7).strip() or "nan")
                result[cat].append(
                    {
                        "problem_type": ptype,
                        "n": n,
                        "acc": acc,
                        "avg_final": avg_final,
                        "avg_fmt": avg_fmt,
                        "avg_corr": avg_corr,
                    }
                )
            except ValueError:
                pass
        row += 1
        if row > 5000:
            break
    return result


def _plot_metric_grid(
    steps: List[int],
    metric_data: Dict[str, Dict[str, List[float]]],
    metrics: List[Tuple[str, str]],
    title: str,
    out_path: str,
) -> None:
    cols = 2
    rows = int(np.ceil(len(metrics) / cols))
    fig, axes = plt.subplots(rows, cols, figsize=(12, 4.2 * rows), sharex=True)
    axes_arr = np.array(axes).reshape(-1)

    for idx, (metric_key, metric_label) in enumerate(metrics):
        ax = axes_arr[idx]
        per_cat = metric_data.get(metric_key, {})
        for cat in CATEGORIES:
            vals = per_cat.get(cat, [float("nan")] * len(steps))
            ax.plot(steps, vals, marker="o", linewidth=2, label=cat, color=CAT_COLORS[cat])
        ax.set_title(metric_label)
        ax.set_xlabel("Step")
        ax.grid(alpha=0.25)
        ax.legend(loc="best")

    # Hide unused subplot axes
    for idx in range(len(metrics), len(axes_arr)):
        axes_arr[idx].axis("off")

    fig.suptitle(title, fontsize=14, fontweight="bold")
    fig.tight_layout()
    fig.savefig(out_path, dpi=180, bbox_inches="tight")
    plt.close(fig)


def _plot_sample_counts(steps: List[int], sample_counts: Dict[str, List[float]], out_path: str) -> None:
    fig, ax = plt.subplots(figsize=(11, 5))
    width = 0.22
    x = np.arange(len(steps))
    for i, cat in enumerate(CATEGORIES):
        vals = sample_counts.get(cat, [float("nan")] * len(steps))
        ax.bar(x + (i - 1) * width, vals, width=width, label=cat, color=CAT_COLORS[cat], alpha=0.9)
    if "Total" in sample_counts:
        ax.plot(x, sample_counts["Total"], marker="s", linewidth=2, color="#444444", label="Total")

    ax.set_xticks(x)
    ax.set_xticklabels([str(s) for s in steps])
    ax.set_xlabel("Step")
    ax.set_ylabel("Samples")
    ax.set_title("Validation Sample Counts by Step")
    ax.grid(axis="y", alpha=0.25)
    ax.legend(loc="best")
    fig.tight_layout()
    fig.savefig(out_path, dpi=180, bbox_inches="tight")
    plt.close(fig)


def _plot_problem_type_bars(
    breakdown: Dict[str, List[Dict[str, float | str]]],
    metric_key: str,
    metric_label: str,
    top_n: int,
    out_path: str,
) -> None:
    fig, axes = plt.subplots(1, 3, figsize=(18, 7), sharex=False)
    for i, cat in enumerate(CATEGORIES):
        ax = axes[i]
        rows = breakdown.get(cat, [])
        if not rows:
            ax.set_title(f"{cat} (no data)")
            ax.axis("off")
            continue

        sorted_rows = sorted(
            rows,
            key=lambda x: float(x.get(metric_key, float("nan"))),
            reverse=True,
        )[:top_n]
        labels = [str(r["problem_type"]) for r in sorted_rows][::-1]
        vals = [float(r[metric_key]) for r in sorted_rows][::-1]

        ax.barh(labels, vals, color=CAT_COLORS[cat], alpha=0.85)
        ax.set_title(f"{cat} Top {len(sorted_rows)} ({metric_label})")
        ax.grid(axis="x", alpha=0.25)
        if metric_key in ("acc",):
            ax.set_xlim(0, 100)
        else:
            ax.set_xlim(0, 1.05)
    fig.suptitle(f"Problem-Type Ranking by {metric_label}", fontsize=14, fontweight="bold")
    fig.tight_layout()
    fig.savefig(out_path, dpi=180, bbox_inches="tight")
    plt.close(fig)


def generate_visualizations(report_path: str, output_dir: str, top_n: int) -> List[str]:
    """Generate chart files from analysis_report.xlsx."""
    sheets = load_xlsx_sheets(report_path)
    required = ["准确率", "Reward指标", "Consistency子指标", "样本数"]
    missing = [s for s in required if s not in sheets]
    if missing:
        raise ValueError(f"Missing required sheet(s): {missing}")

    os.makedirs(output_dir, exist_ok=True)
    plt.style.use("default")

    steps = _parse_steps(sheets["样本数"])
    accuracy = _parse_category_metric_trends(
        sheets["准确率"],
        {2: "acc", 3: "fmt_acc"},
        len(steps),
    )
    rewards = _parse_category_metric_trends(
        sheets["Reward指标"],
        {2: "final_reward", 3: "format_reward", 4: "correctness_reward", 5: "consistency_reward"},
        len(steps),
    )
    consistency_sub = _parse_category_metric_trends(
        sheets["Consistency子指标"],
        {2: "coverage_reward", 3: "order_reward", 4: "binding_reward", 5: "intermediate_reward"},
        len(steps),
    )
    sample_counts = _parse_sample_counts(sheets["样本数"], len(steps))
    breakdown = _parse_problem_breakdown(sheets.get("题型细分"))

    out_files: List[str] = []

    p1 = os.path.join(output_dir, "01_accuracy_trends.png")
    _plot_metric_grid(
        steps=steps,
        metric_data=accuracy,
        metrics=[("acc", "Accuracy (%)"), ("fmt_acc", "Format Accuracy (%)")],
        title="Accuracy Trends by Category",
        out_path=p1,
    )
    out_files.append(p1)

    p2 = os.path.join(output_dir, "02_reward_trends.png")
    _plot_metric_grid(
        steps=steps,
        metric_data=rewards,
        metrics=[
            ("final_reward", "Final Reward"),
            ("format_reward", "Format Reward"),
            ("correctness_reward", "Correctness Reward"),
            ("consistency_reward", "Consistency Reward"),
        ],
        title="Reward Trends by Category",
        out_path=p2,
    )
    out_files.append(p2)

    p3 = os.path.join(output_dir, "03_consistency_submetrics.png")
    _plot_metric_grid(
        steps=steps,
        metric_data=consistency_sub,
        metrics=[
            ("coverage_reward", "Coverage"),
            ("order_reward", "Order"),
            ("binding_reward", "Binding"),
            ("intermediate_reward", "Intermediate"),
        ],
        title="Consistency Sub-metrics by Category",
        out_path=p3,
    )
    out_files.append(p3)

    p4 = os.path.join(output_dir, "04_sample_counts.png")
    _plot_sample_counts(steps=steps, sample_counts=sample_counts, out_path=p4)
    out_files.append(p4)

    if any(breakdown.get(cat) for cat in CATEGORIES):
        p5 = os.path.join(output_dir, "05_problem_type_top_acc.png")
        _plot_problem_type_bars(
            breakdown=breakdown,
            metric_key="acc",
            metric_label="Accuracy (%)",
            top_n=top_n,
            out_path=p5,
        )
        out_files.append(p5)

        p6 = os.path.join(output_dir, "06_problem_type_top_final_reward.png")
        _plot_problem_type_bars(
            breakdown=breakdown,
            metric_key="avg_final",
            metric_label="Avg Final Reward",
            top_n=top_n,
            out_path=p6,
        )
        out_files.append(p6)

    return out_files


def main() -> None:
    parser = argparse.ArgumentParser(description="Visualize analysis_report.xlsx into PNG charts.")
    parser.add_argument("report", help="Path to analysis_report.xlsx")
    parser.add_argument(
        "--output-dir",
        "-o",
        default=None,
        help="Output directory for chart PNGs (default: <report_dir>/charts)",
    )
    parser.add_argument("--top-n", type=int, default=10, help="Top-N problem types to plot per category")
    args = parser.parse_args()

    report_path = os.path.abspath(args.report)
    if not os.path.exists(report_path):
        raise FileNotFoundError(f"Report not found: {report_path}")

    out_dir = os.path.abspath(args.output_dir) if args.output_dir else os.path.join(os.path.dirname(report_path), "charts")

    out_files = generate_visualizations(report_path=report_path, output_dir=out_dir, top_n=args.top_n)
    print(f"✅ Generated {len(out_files)} chart file(s) in: {out_dir}")
    for fp in out_files:
        print(f" - {fp}")


if __name__ == "__main__":
    main()
